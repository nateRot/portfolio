{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://img.icons8.com/dusk/64/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 044165/6 - Technion - Intro to Machine Learning Lab\n",
    "\n",
    "## Part 2 - K-NN and Perceptron\n",
    "\n",
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "\n",
    "* Recap of Part 1\n",
    "    * Loading the Data\n",
    "    * Data Representation\n",
    "    * Train-Test Separation\n",
    "    * Naive Bayes\n",
    "* K Nearset Neighbors (K-NN)\n",
    "* The Perceptron\n",
    "* Final Comparison\n",
    "\n",
    "#### Notes\n",
    "* To run a code block, select it (with mouse) and press Ctrl + Enter to run it or Shift + Enter to run it and move on to the next block.\n",
    "* To get description of functions and classes, run `help(name_of_function)`.\n",
    "* To display lines in the code block, select the block, press ESC and then 'L'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the lab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from helper_functions import email_pipeline\n",
    "from tqdm import tqdm\n",
    "# import K-NN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import TF-IDF pre-processor\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/rewind.png\" style=\"height:50px;display:inline\"> Recap of Part 1\n",
    "We will now repeat the process of of loading the data, pre-processing it and splitting it.\n",
    "\n",
    "#### Copy & Paste relevant code from the previous lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "\"\"\"Starter code\n",
    "# email_data = \n",
    "\"\"\"\n",
    "email_data = pd.read_csv('./email_data.csv')\n",
    "''' END OF SOLUTION !!!! '''\n",
    "# let's look at 15 random samples from it.\n",
    "email_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = email_data['Content'].values\n",
    "y = email_data['Label'].values == 'S' # 1 Spam, 0 for Ham\n",
    "\n",
    "# split to train and test\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "# transform using email_pipeline\n",
    "X_train_augmented =\n",
    "X_test_augmented =\n",
    "\n",
    "\n",
    "# get statistics\n",
    "print(\"num train samples: \", X_train.shape[0])\n",
    "print(\"num test samples: \", X_test.shape[0])\n",
    "print(\"shape after augmentation: \", X_train_augmented.shape)\n",
    "print(\"fraction of spam in the original: \", np.mean(y == 1))\n",
    "print(\"fraction of spam in the train set: \", np.mean(y_train == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  run this cell\n",
    "#  (is just the estimate_likelihood_params function from previous time)\n",
    "\n",
    "def estimate_likelihood_params(X, y, dist_type=\"gaussian\", c=0.5, num_classes=2):\n",
    "    \"\"\"\n",
    "    Calculate the likelihood P(X|y,theta)\n",
    "    :param X: features\n",
    "    :param y: labels\n",
    "    :param dist_type: type of distribution: \"gaussian\", \"bernoulli\", \"multinomial\", \"multinomial_smooth\"\n",
    "    :param c: smoothing parameter for \"multinomial_smooth\"\n",
    "    :param num_classes: number of classes\n",
    "    :return likelihood_params\n",
    "    \"\"\"\n",
    "    if isinstance(X, csr_matrix):\n",
    "        X = X.todense()\n",
    "    n_samples = X.shape[0]\n",
    "    n_feat = X.shape[1]\n",
    "    params = {'type': dist_type}\n",
    "    if dist_type == 'gaussian':\n",
    "        mu_s = np.zeros((num_classes, n_feat))\n",
    "        sigmaSqr_s = np.zeros((num_classes, n_feat))\n",
    "        for i_class in range(num_classes):\n",
    "            mu_s[i_class] = X[y == i_class].mean(axis=0)\n",
    "            sigmaSqr_s[i_class] = np.square(X[y == i_class] - mu_s[i_class]).mean(axis=0)\n",
    "        params['mu'] = mu_s\n",
    "        params['sigmaSqr'] = sigmaSqr_s\n",
    "\n",
    "    elif dist_type == 'bernoulli':\n",
    "        p_s = np.zeros((num_classes, n_feat))\n",
    "        for i_class in range(num_classes):\n",
    "            x_i = X[y == i_class]\n",
    "            # change to 0-1 (binary features)\n",
    "            x_i[x_i > 0] = 1\n",
    "            p_s[i_class] = x_i.mean(axis=0)\n",
    "        params['p'] = p_s\n",
    "\n",
    "    elif dist_type == 'multinomial':\n",
    "        p_s = np.zeros((num_classes, n_feat))\n",
    "        for i_class in range(num_classes):\n",
    "            x_i = X[y == i_class]\n",
    "            T = np.sum(x_i)\n",
    "            p_s[i_class] = np.sum(x_i, axis=0) / T\n",
    "        params['p'] = p_s\n",
    "    elif dist_type == 'multinomial_smooth':\n",
    "        p_s = np.zeros((num_classes, n_feat))\n",
    "        for i_class in range(num_classes):\n",
    "            x_i = X[y == i_class]\n",
    "            T = np.sum(x_i[:]) + c * n_feat\n",
    "            p_s[i_class] = (c + np.sum(x_i, axis=0)) / T\n",
    "        params['p'] = p_s\n",
    "    else:\n",
    "        print(\"unknown distribution!\")\n",
    "        return\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste your implemented Naive Bayes Classifier and implemented function calc_err to use later\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "Paste here your MlabNaiveBayes class and your calc_err function\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  complete the following function\n",
    "\n",
    "def evaluate_classifier(clf, X, y, test_size=0.2, num_repeats=20):\n",
    "    current_errors = np.zeros(num_repeats)\n",
    "    for i_rep in tqdm(range(num_repeats)):\n",
    "        \"\"\"\n",
    "        Your Code Here\n",
    "        \"\"\"\n",
    "        # split and pre-process\n",
    "        X_train, X_test, y_train, y_test =\n",
    "        X_augmented_train =\n",
    "        X_augmented_test =\n",
    "        # train\n",
    "        \n",
    "        \n",
    "        # test\n",
    "        y_pred =\n",
    "        calculate error\n",
    "        current_errors[i_rep] =\n",
    "     \n",
    "    error_mean = np.mean(current_errors)\n",
    "    error_std = np.std(current_errors)\n",
    "    return error_mean, error_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/rewind.png\" style=\"height:50px;display:inline\"> K Nearest Neighbors\n",
    "We will now use K-NN classifier to complete the classification task. You will use Scikit-Learn's K-NN Classifier `KNeighborsClassifier`.\n",
    "\n",
    "Usage:\n",
    "\n",
    "`clf = KNeighborsClassifier(n_neighbors=K, p=2)` or `KNeighborsClassifier(n_neighbors=K, metric='cosine')`\n",
    "\n",
    "`clf.fit(X_augmented_train, y_train)`\n",
    "\n",
    "`y_pred = clf.predict(X_augmented_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using distances:\n",
    "# L2 - p=2 [KNeighborsClassifier(n_neighbors=K, p=2)]\n",
    "# L1 - p=1 [KNeighborsClassifier(n_neighbors=K, p=1)]\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "\n",
    "# num neighbors\n",
    "K =\n",
    "\n",
    "# L2 distance\n",
    "\n",
    "print(\"l2 error: {}, std: {}\".format(l2_error, l2_error_std))\n",
    "\n",
    "# L1 distance\n",
    "\n",
    "print(\"l1 error: {}, std: {}\".format(l1_error, l1_error_std))\n",
    "\n",
    "# Cosine distance\n",
    "\n",
    "print(\"cosine dist error: {}, std: {}\".format(cos_error, cos_error_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary table\n",
    "summary_df = pd.DataFrame(np.concatenate([np.array([l2_error, l1_error, cos_error]).reshape(-1, 1),\n",
    "                                       np.array([1 - l2_error, 1 - l1_error, 1 - cos_error]).reshape(-1, 1),\n",
    "                                       np.array([l2_error_std, l1_error_std, cos_error_std]).reshape(-1,1)],axis=1),\n",
    "                       columns=['Error', 'Accuracy', 'Error STD'], index=['L2', 'L1', 'Cosine'])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance vs. K\n",
    "K_s = [1, 3, 5, 7, 15]  # num neighbors\n",
    "# using distances:\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "num_repeats = 10\n",
    "K_errors = np.zeros(len(K_s))\n",
    "K_errors_std = np.zeros(len(K_s))\n",
    "\n",
    "\"\"\"\n",
    " Your Code Here\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "Use ax.errorbar()\n",
    "\"\"\"\n",
    "\n",
    "ax.set_xlabel(\"number of neighbors (K)\")\n",
    "ax.set_ylabel(\"error %\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.grid()\n",
    "ax.set_title(\"Test Error vs. Number of Neigbors (N={} Repeats)\".format(num_repeats))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/color/96/000000/transformer.png\" style=\"height:50px;display:inline\"> TF-IDF Transformation\n",
    "We will now apply TF-IDF transformation as another pre-proccessing stage of the data.\n",
    "\n",
    "Usage:\n",
    "\n",
    "`tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)`\n",
    "\n",
    "`X_augmented_tfidf_train = tfidf_transformer.fit_transform(X_augmented_train)`\n",
    "\n",
    "`X_augmented_tfidf_test = tfidf_transformer.transform(X_augmented_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3  # num neighbors\n",
    "# using distances:\n",
    "# Cosine Distance - metric='cosine' [KNeighborsClassifier(n_neighbors=K, metric='cosine')]\n",
    "\n",
    "num_repeats = 10\n",
    "test_size = 0.2\n",
    "\n",
    "current_errors = np.zeros(num_repeats)\n",
    "current_errors_tfidf = np.zeros(num_repeats)\n",
    "\n",
    "for i_rep in tqdm(range(num_repeats)):\n",
    "    \"\"\"\n",
    "    Your Code Here\n",
    "    \"\"\"\n",
    "    \"\"\" Starter code     \"\"\"\n",
    "    # split and pre-process\n",
    "    X_train, X_test, y_train, y_test =\n",
    "    X_augmented_train =\n",
    "    X_augmented_test =\n",
    "\n",
    "    # train without TF-IDF\n",
    "    clf =\n",
    "    # test\n",
    "    y_pred =\n",
    "    # calculate error\n",
    "    current_errors[i_rep] =\n",
    "\n",
    "    # train with TF-IDF\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    X_augmented_tfidf_train =\n",
    "    X_augmented_tfidf_test =\n",
    "    clf_tfidf =\n",
    "    # test\n",
    "    y_pred_tfidf =\n",
    "    # calculate error\n",
    "    current_errors_tfidf[i_rep] =\n",
    "\n",
    "\n",
    "cos_error = np.mean(current_errors)\n",
    "cos_error_std = np.std(current_errors)\n",
    "print(\"cosine dist error: {}, std: {}\".format(cos_error, cos_error_std))\n",
    "cos_error_tfidf = np.mean(current_errors_tfidf)\n",
    "cos_error_std_tfidf = np.std(current_errors_tfidf)\n",
    "print(\"cosine dist error with TF-IDF: {}, std: {}\".format(cos_error_tfidf, cos_error_std_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary table\n",
    "summary_df = pd.DataFrame(np.concatenate([np.array([cos_error, cos_error_tfidf]).reshape(-1, 1),\n",
    "                                       np.array([1 - cos_error, 1 - cos_error_tfidf]).reshape(-1, 1),\n",
    "                                       np.array([cos_error_std, cos_error_std_tfidf]).reshape(-1,1)],axis=1),\n",
    "                       columns=['Error', 'Accuracy', 'Error STD'], index=['Cosine' ,'Cosine with TD-IDF'])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/artificial-intelligence.png\" style=\"height:50px;display:inline\"> The Perceptron\n",
    "We will now implement the Perceptron and test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "class MlabPerceptron():\n",
    "    \"This class implements a Perceptron Classifier\"\n",
    "\n",
    "    def __init__(self, num_epochs=10, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the classfier\n",
    "        :param num_epochs: how many epochs to run on the data\n",
    "        :param alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.num_epochs = num_epochs\n",
    "        self.alpha = alpha\n",
    "        self.w = None  # no weights\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        \"\"\"\n",
    "        Train the classfier\n",
    "        :param X: features\n",
    "        :param y: labels\n",
    "        \"\"\"\n",
    "        if isinstance(X, csr_matrix):\n",
    "            X = X.todense()\n",
    "        y = np.array(y, dtype=np.int)\n",
    "        y[y == 0] = -1  # convert 0 -> -1\n",
    "        num_samples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        # initialize weights\n",
    "        self.w = np.ones((1, num_features + 1))\n",
    "        # train\n",
    "        for epoch in range(self.num_epochs):\n",
    "            num_updates = 0  # how many updates were performed\n",
    "            \"\"\"\n",
    "            Your Code Here\n",
    "            Remember that you have 2 stopping criteria\n",
    "            1. Reached maximum number of epochs\n",
    "            2. No more updates to the weights\n",
    "            \"\"\"\n",
    "            for i_samp in range(num_samples):\n",
    "                # concatenate 1 to feature vector\n",
    "                sample = np.append(X[i_samp], np.ones((1,1)), axis=1)\n",
    "                \n",
    "                \n",
    "            # end for i_samp\n",
    "            if num_updates == 0:\n",
    "                \n",
    "            \n",
    "            if verbose:\n",
    "                print(\"epoch {}: {} updates\".format(epoch, num_updates))\n",
    "        # end for epoch\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels for features\n",
    "        :param X: features\n",
    "        :return y_pred: predictions\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            print(\"can't call 'predict' before 'fit'\")\n",
    "            return\n",
    "        num_samples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        if isinstance(X, csr_matrix):\n",
    "            X = X.todense()\n",
    "        \"\"\"\n",
    "        Your Code Here\n",
    "        \"\"\"\n",
    "        \"\"\" Starter code     \"\"\"\n",
    "        \n",
    "        for i_samp in range(num_samples):\n",
    "            # concatenate 1 to feature vector\n",
    "            sample = np.append(X[i_samp], np.ones((1,1)), axis=1)\n",
    "\n",
    "            \n",
    "        # end for i_samp\n",
    "        y_pred[y_pred == -1] = 0  # convert back -1 -> 0\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's see it in action\n",
    "\n",
    "X = email_data['Content'].values\n",
    "y = email_data['Label'].values == 'S'  # 1 Spam, 0 for Ham\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_augmented_train = email_pipeline.fit_transform(X_train)\n",
    "X_augmented_test = email_pipeline.transform(X_test)\n",
    "\n",
    "# train and test\n",
    "perc_clf = MlabPerceptron(num_epochs=10, alpha=0.5)\n",
    "perc_clf.fit(X_augmented_train, y_train, verbose=True)\n",
    "y_pred = perc_clf.predict(X_augmented_test)\n",
    "print(\"Pereceptron error (using only 10 epochs): \", calc_err(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the weights\n",
    "print(perc_clf.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 20\n",
    "num_epochs = 50\n",
    "\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"perceptron error: {}, std: {}\".format(perc_error, perc_error_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n",
    "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/\n",
    "* Notebook made by <a href=\"mailto:taldanielm@campus.technion.ac.il\">Tal Daniel</a>\n",
    "* Updates: Ron Amit (March 2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}